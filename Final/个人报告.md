# <center>FINAL个人报告</center>

<center>葉珺明 19335253</center>



---



## 主要完成工作：

+ 对baseline版本的优化：

  + 使用共享内存：

    在baseline版本中，所有数据存储在全局内存中，对数据进行处理时也是采用访问全局内存的方式，每个线程都进行了相同的操作，对全局内存进行了频繁的读操作。而全局内存的访问时间长。考虑使用共享内存以降低数据访问的耗时，在同一线程块下的数据可以存储到共享内存中，对数据进行操作时访问共享内存，能够提高数据的访问速度，从而提高线程运行效率。

    改写后的代码：

    ```c
    __global__ void kmeans(float *data, float *kcen, int *symbols){
        const int tid_x = blockIdx.x * blockDim.x + threadIdx.x; //col
        const int tid_y = blockIdx.y * blockDim.y + threadIdx.y; //row
        const int threadId = tid_x+tid_y*blockDim.x*gridDim.x;
       
        const int sid_x = threadIdx.x; //col
        const int sid_y = threadIdx.y; //row
    
        __shared__ float sdata_x[32*32];
        __shared__ float sdata_y[32*32];
    
        sdata_x[sid_y*32+sid_x] = data[2*threadId];
        sdata_y[sid_y*32+sid_x] = data[2*threadId+1];
    
        __syncthreads();
    
        float x = sdata_x[sid_y*32+sid_x];
        float y = sdata_y[sid_y*32+sid_x];
    
        // const int threadId = tid_x+tid_y*blockDim.x*gridDim.x;
        // float x = data[2*(threadId)];
        // float y = data[2*(threadId)+1];
    
        float min = powf(x-kcen[0],2)+powf(y-kcen[1],2);
        int c = 0;
        
        for(int i=2;i<2*k;i+=2){
            float ds = powf(x-kcen[i],2)+powf(y-kcen[i+1],2);
            if(min > ds){
                min = ds;
                c = i/2;
            }
        }
        symbols[threadId] = c;
        // printf("threadID: %d\n", threadId);
    }
    ```

  + 将控制密集型任务转移到**CPU**上进行：在baseline版本中，对聚类中心的更新的所有操作是在GPU上进行的，但对于每个类别下的数据求和分析需要大量访问全局内存，并且更新的操作中涉及密集的原子操作，在较密集的情况下，采用原子操作会有大量的时间在等待，故没有采用原子操作。而是将更新操作的部分移动到CPU上，增加了数据在GPU和CPU上的通信时间但减少GPU对控制事务的处理和原子操作的等待时间.

+ 优化后的实验结果：

  数据量越大，加速比越高，在数据量为4194304时，加速比达到7.5倍左右：
  
  <img src="C:\Users\YIP\AppData\Local\Temp\WeChat Files\b2543865f501bc84f3f17706f65e67b.png" alt="b2543865f501bc84f3f17706f65e67b" style="zoom:80%;" />
  
    

## 实验心得：

主要是对GPU的性能影响因素有了更深刻的了解：

+ 核函数需要不断去优化，考虑数据的使用从而存储到合适的位置
+ 核函数中应尽量减少逻辑分支，GPU适合数据密集型任务，而CPU适合控制密集型任务，将逻辑处理交由CPU处理，高效结合CPU和GPU
+ 线程块的设计，在数据量较大时，需要对线程块和线程分配进行合理的安排；数据量十分大时的通信优化。